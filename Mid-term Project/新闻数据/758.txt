“深度造假”视频危害日益加剧
原标题：“深度造假”视频危害日益加剧    来源：科技日报
原标题：李鬼变李逵！“深度造假”视频危害日益加剧
相机应用变得越来越复杂。用户可以拉长腿部，去除脸上的粉刺，加上动物耳朵等等。现在，有些人甚至可以制作出看起来非常逼真的虚假视频。用来创造这类数字内容的技术已经“飞入寻常百姓家”，被称为“深度造假”。
美国消费者新闻与商业频道网站（CNBC）在近日的报道中指出，随着技术的不断进步，“李鬼变李逵”！“深度造假”的危害日益加剧，正带来一系列具有挑战性的政策、技术和法律问题。
深度学习+造假=深度造假
“深度造假”是指经过处理的视频，或者通过尖端的人工智能技术生成的其他数字内容，它们会产生看似真实的虚假图像和声音。
“深度造假”这个词结合了“深度学习”和“造假”，是一种人工智能形式。深度学习是人工智能的一个子集，指的是能够学习和自行做决定的一些算法。
美国纽约大学法学兼职教授保罗·巴雷特说，简单来讲，“深度造假”就是借助深度学习手段制作的虚假视频。深度学习系统可以从多个角度研究目标人物的照片和视频，然后模仿其行为和说话模式，从而制造出具有说服力的虚假内容。
巴雷特解释说：“一旦制造出了初步的假象，就可以通过名为‘生成式对抗网络’（GAN）的方法让它看起来更加可信。GAN可发现伪造过程中的瑕疵，从而改进这些瑕疵。经过多轮检查和改进后，‘深度造假’视频就完成了。”
在公共政策机构布鲁金斯学会下设的技术革新中心从事治理研究的非常驻高级研究员、加利福尼亚大学洛杉矶分校电子工程系教授约翰·维拉塞纳认为，从技术的角度来说，任何人只要拥有电脑并且能够上网，就可以制造“深度造假”的内容。
“李鬼变李逵”
智库新美国（New America）关注网络安全与防御的战略家、高级研究员彼得·辛格指出，“深度造假”的危险在于，这种技术可以让人相信原本并不真实存在的东西是真实的。
辛格不是唯一一个提醒“深度造假”所带来的危险的人。
维拉塞纳也表示，这类视频“变得越来越复杂、越来越容易制作，‘深度造假’正带来一系列具有挑战性的政策、技术和法律问题”。这项技术“可以让政治候选人看上去像是说了或做了什么从未真正说过的话或做过的事，以此来破坏他们的声誉”。
麻省理工学院的一项技术报告指出，可以进行“深度造假”的设备可能成为“伪造虚假新闻者的理想武器，他们希望影响从股票价格到选举的一切”。
CNBC网站在其报道中称，“深度造假”将成为“2020年美国总统选举中的大事件”。就像2016年的“虚假新闻”一样，“深度造假”视频将在2020年的美国大选中，掀起更强大的血雨腥风。当然，为了未雨绸缪，包括加州和德州在内的不少州都已经制定法律，当这些“深度造假”视频用于2020年的选举中时，将被认为不合法。
《麻省理工学院技术评论》杂志旧金山分支机构负责人马丁·贾尔斯在一份报告中写道，事实上，“人工智能工具已被用于把其他人的面部照片安在色情明星身上，让其他人说的话从政客们的口中说出。”他说，这个问题并非由GAN制造，但GAN会让问题变得更糟糕。
成也萧何败也萧何
正所谓成也萧何败也萧何！维拉塞纳今年2月份曾撰文指出，虽然人工智能可以用来生成“深度造假”视频，但也可以用来检测它们。由于任何计算机用户都可以使用该技术，越来越多的研究人员将注意力集中在“深度造假”视频的检测上，并且正在殚精竭虑地寻求管控这些“深度造假”视频的方法。
脸书和微软等大公司已经采取行动，旨在发现并删除“深度造假”视频。据路透社报道，这两家公司于今年早些时候宣布，他们将与美国顶级大学合作，建立一个庞大的假视频数据库，以进行深入的分析研究。
辛格指出，普通用户也可以用自己的双眼来观测并检查出“深度造假”视频。他说：“目前，如果你近距离观察，会出现一些轻微的突兀之处，比如耳朵或眼睛不匹配、脸部轮廓模糊、皮肤太光滑等等。”
但是他也强调，随着“深度造假”技术日益精进，视频会看起来越来越真实，人们要分辨也变得越来越困难。
维拉塞纳也提醒人们，在技术不断发展演进的同时，用来发现造假的检测技术“往往落后于最先进的生成造假的手法”。因此，更值得深思的一个问题是：人们更有可能相信“深度造假”视频，还是将这类视频作为“深度造假”的检测算法？
