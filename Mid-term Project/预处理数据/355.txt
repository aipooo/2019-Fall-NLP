原 标题 跑分 对决 平台 运行 模型 推理 更 快 来源 量子 位
关注 前沿 科技
量子 位
一 项 不可 忽略 的 因素 二者 的 实际 性能
没关系 不服 跑 个 分
最近 一 位 来自 的 工程师 使用 中 的 模型 分别 在 两 大 平台 上 测试 一 组 推理 速度
一家 创业 公司 在 领域 有着 不 小 的 声誉 在 上 开源 的 项目 只 需 一个 就 能 调用 个 模型 广受 好评 已经 收获
万星
和 更 快
下面 用 详细 评测 的 数据 告诉
运行 环境
作者 在


上 分别 对 和 的 推理 性能 进行 测试
两 种 的 环境 中 具体 硬件 配置
推理 使用 谷歌 云 平台 上 的 硬件 即 个 内存 型号 为
的 英特尔 至强 处理器
推理 使用 谷歌 云 平台 上 的 定制化 硬件 包含 个 内存 和 单个 显存
在 测试 过程 中 使用 本地 模块 的 来 测量 推理 时间
每个 实验 重复 次 对 值取 平均值 获得 平均 推理 时间
模型 的 设置 为 分别 设置 为 序列 长度 为
测试
话 不 多 说 先 上 跑分
在 大多数 情况 下 这 两 个 平台 都 能 获得 相似 的
与 相比 在 上 通常 要 慢 一些 但 在 上 要 快 一些
在 上 的 平均 推理 时间 为
而 的 平均 推理 时间 为

在 上 的 平均 推理 时间 为
而 的 平均 推理 时间 为

以上 的 数据 都 是 在 所有 模型 总 的 平均
显示 输入 大小 序列 长度 越 大 对 最终 的 影响 也 越 大
当 输入 太 大 时 出现 内存 不足 的 情况
作者 部分 从 中 删除 这 使 偏向
模型 比 模型 更 容易 耗尽 内存
模型 之外 当 输入 大小 达到 的 和 的 序列 长度 时 就 耗尽 内存
更 完整 详细 的 清单 请 参阅 文末 的 文档 链接
两 大 平台 的 加速 工具
初步 的 测试 作者 还 用 上 两 个 平台 独有 的 加速 工具 看看 对 模型 推理 速度 有 多 大 的 提升
是 创建 可 序列化 模型 的 方法 让 模型 在 的 环境 中 运行 而 无需 依赖 项 环境
似乎 依赖于 模型 和 输入 大小
使用 在 上 产生 永久 的 性能 提升 而 在 上 使用 则 不 可靠
在 上 提高 较 小 输入 时 的 性能 但 降低 较 大 输入 时 的 性能
平均 使用 跟踪 的 模型 推理 速度 要 比 使用 相同 非 跟踪 模型 的 快
是 可 加速 模型 的 线性 代数 编译器
作者 仅 在 的 自动 聚类 功能 的 上 使用 这项 功能 可 编译 一些 模型 的 子图
显示
启用 提高 速度 和 内存 使用率 所有 模型 的 性能 都 有 提高
大多数 基准 测试 的 运行 速度 提升 到 原来 的
倍
在 情况 下 推理 时间 减少 尤其 是 在 输入 较 小 的 情况 下
作者 还 在 文档 的 列表 里 还 加入 训练 选项卡 不久后 就 能 看到 两 大 平台 上 的 训练 测试 对比 唯一 挡 在 这项 测试 面前 的 障碍 经费
传送门
声明 本文 仅 代表 作者 观点 不 代表 新浪网 立场

